Metadata-Version: 2.4
Name: spacex-landing
Version: 0.1.0
Summary: End-to-end data science project: predict SpaceX Falcon 9 first-stage landing success.
Author: Your Name
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Dynamic: license-file

# SpaceX Falcon 9 Landing Success Prediction

An end-to-end data science project that predicts whether a **Falcon 9 first-stage**
will successfully land, using historical launch data.

This repo includes:
- reproducible data collection utilities (SpaceX API + optional Wikipedia scraping)
- wrangling + feature engineering helpers
- model training with cross-validated grid search
- an interactive Plotly Dash dashboard 


---

## Why this project

Reusable rocket stages dramatically reduce launch costs. Predicting landing success helps
understand which factors (payload mass, orbit, launch site, booster version, etc.) correlate
with successful recovery.

---

## Repo layout

- `src/spacex_landing/` — reusable Python package (collection, wrangling, modeling, dashboard)
- `scripts/` — command-line scripts (dataset build, model-table prep, training)
- `notebooks/original/` — original lab notebooks (provenance + traceability)
- `notebooks/clean/` — exported `.py` versions of notebooks (bridge toward production code)
- `docs/` — specs/reference material (e.g., dashboard requirements PDF)
- `data/` — raw/processed datasets (gitignored by default)
- `models/` — trained model artifacts (gitignored by default)
- `reports/` — metrics and figures

---

## Quickstart

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
pip install -e .
```

### Dev tooling (lint + tests)

```bash
pip install -r requirements-dev.txt
ruff check .
pytest -q
```

---

## Reproduce the pipeline

### 1) Build a minimal dataset from the SpaceX API

```bash
python scripts/make_dataset.py --out data/processed/dataset.csv
```

This produces a **minimal** table for demonstration. For a richer, lab-equivalent feature table,
use the notebooks to build a feature table and export it as CSV.

### 2) Prepare a model-ready table (one-hot + numeric)

Given an input CSV feature table (exported from notebooks):

```bash
python scripts/prepare_model_table.py --in data/processed/feature_table.csv --out data/processed/model_table.csv
```

The training script expects `model_table.csv` to contain:
- a binary target column: `Class`
- all remaining columns numeric / one-hot encoded

### 3) Train + pick the best model (grid search)

```bash
python scripts/train_model.py   --data data/processed/model_table.csv   --model_out models/best_model.joblib
```

Outputs:
- `models/best_model.joblib`
- `reports/metrics.json`

---

## Run the interactive Dash dashboard

1) Download the dataset used by the lab:

```bash
python scripts/make_dashboard_dataset.py --out data/raw/spacex_launch_dash.csv
```

2) Run the app:

```bash
python -m spacex_landing.dashboard.app --data data/raw/spacex_launch_dash.csv
```

Then open: `http://localhost:8050`

---

## Results (fill this in as you finalize)

After you export `feature_table.csv` from your notebook pipeline and run:

- `scripts/prepare_model_table.py`
- `scripts/train_model.py`

…paste the best model + metrics from `reports/metrics.json` here, and optionally add screenshots to `reports/figures/`.

Example:

- **Best model:** SVM
- **Accuracy:** 0.83
- **F1:** 0.81

---

## License

MIT (see `LICENSE`).
